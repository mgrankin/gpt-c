{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-courage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infectious-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from haiku import LayerNorm\n",
    "from einops import rearrange, repeat\n",
    "from functools import lru_cache, partial\n",
    "\n",
    "# there is no limit for lenght of text, because our countext windows is always 75 tokens, \n",
    "# but we have to choose for RoPE\n",
    "MAX_SEQ_LEN = 8192\n",
    "\n",
    "@lru_cache()\n",
    "def fixed_pos_embedding(rotary_dims):\n",
    "    inv_freq = 1. / (10000 ** (np.arange(0, rotary_dims, 2) / rotary_dims))\n",
    "    sinusoid_inp = np.einsum('i , j -> i j', np.arange(MAX_SEQ_LEN), inv_freq)\n",
    "    return np.sin(sinusoid_inp), np.cos(sinusoid_inp)\n",
    "\n",
    "def rotate_every_two(x):\n",
    "    x1 = x[..., ::2]\n",
    "    x2 = x[..., 1::2]\n",
    "    x = jnp.stack((-x2, x1), axis=-1)\n",
    "    return rearrange(x, '... d j -> ... (d j)')\n",
    "\n",
    "def apply_rotary_pos_emb(x, sincos, seq_dim):\n",
    "    sincos = map(lambda t: repeat(t, '... b n -> ... b (n j)', j=2)[-x.shape[seq_dim]:], sincos)\n",
    "    \n",
    "    # (n_seq, dim_per_head) -> (n_seq, 1, 1, dim_per_head), so we can do mult\n",
    "    # in case \"x\" is something like (n_seq, bs, n_heads, dim_per_head)\n",
    "    add_dims = set(np.arange(x.ndim-1)) - set([np.arange(x.ndim)[seq_dim]])\n",
    "    sin, cos = map(lambda t: jnp.expand_dims(t, tuple(add_dims)), sincos)\n",
    "    \n",
    "    return (x * cos) + (rotate_every_two(x) * sin)\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1,2))\n",
    "def apply_rope(x, rotary_dims, seq_dim):\n",
    "    x_rot = x[..., :rotary_dims]\n",
    "    x_pass = x[..., rotary_dims:]\n",
    "    sincos = fixed_pos_embedding(rotary_dims)\n",
    "    x_rot = apply_rotary_pos_emb(x_rot, sincos, seq_dim)\n",
    "    return jnp.concatenate([x_rot, x_pass], axis=-1)\n",
    "\n",
    "def rope_tests():\n",
    "    rotary_dims = 32\n",
    "    vectors = np.random.random(size=(2,75))\n",
    "    def test_pos(pos1, pos2, f):\n",
    "        q = np.zeros(shape=(1,64,75))\n",
    "        v = np.zeros(shape=(1,64,75))\n",
    "        q[0,pos1] = vectors[0]\n",
    "        v[0,pos2] = vectors[1]\n",
    "        res = f(q,rotary_dims)@f(v,rotary_dims).transpose(0, 2, 1)\n",
    "        return res[0,pos1,pos2]\n",
    "    \n",
    "    pos0 = test_pos(3,17, lambda x,y: x)\n",
    "    pos1 = test_pos(3,17, apply_rope)\n",
    "    pos2 = test_pos(5,19, apply_rope)\n",
    "    pos3 = test_pos(5,20, apply_rope)\n",
    "    assert not jnp.isclose(pos0, pos1)\n",
    "    assert jnp.isclose(pos1, pos2)\n",
    "    assert not jnp.isclose(pos2, pos3)\n",
    "\n",
    "#rope_tests()\n",
    "\n",
    "def rope_tests2():\n",
    "    rotary_dims = 32\n",
    "    vectors = np.random.random(size=(2,75))\n",
    "    def test_pos(pos1, pos2, f):\n",
    "        q = np.zeros(shape=(64,75))\n",
    "        v = np.zeros(shape=(64,75))\n",
    "        q[pos1] = vectors[0]\n",
    "        v[pos2] = vectors[1]\n",
    "        q = q[:,None,None,:]\n",
    "        v = v[:,None,None,:]\n",
    "        q = f(q,rotary_dims,0).transpose(1,2,0,3)\n",
    "        v = f(v,rotary_dims,0).transpose(1,2,0,3)\n",
    "        q = jnp.squeeze(q)\n",
    "        q = jnp.squeeze(q)\n",
    "        v = jnp.squeeze(v)\n",
    "        v = jnp.squeeze(v)\n",
    "        res = q@v.transpose()\n",
    "        return res[pos1,pos2]\n",
    "    \n",
    "    pos0 = test_pos(3,17, lambda x,y,z: x)\n",
    "    pos1 = test_pos(3,17, apply_rope)\n",
    "    pos2 = test_pos(5,19, apply_rope)\n",
    "    pos3 = test_pos(5,20, apply_rope)\n",
    "    assert not jnp.isclose(pos0, pos1)\n",
    "    assert jnp.isclose(pos1, pos2)\n",
    "    assert not jnp.isclose(pos2, pos3)\n",
    "\n",
    "#rope_tests2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "induced-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(hk.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_heads: int,\n",
    "            head_size: int,\n",
    "            rotary_dims: int, \n",
    "            w_init_scale: float,\n",
    "            attn_mask: jnp.ndarray = None,\n",
    "            name: str = \"mha\",\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.model_size = head_size * num_heads\n",
    "        self.w_init = hk.initializers.VarianceScaling(w_init_scale)\n",
    "        self.attn_mask = attn_mask\n",
    "        self.rotary_dims = rotary_dims\n",
    "\n",
    "        self.in_proj_weight = hk.get_parameter(\"in_proj_weight\", shape=[self.model_size * 3, self.model_size], init=self.w_init)\n",
    "        self.in_proj_bias = hk.get_parameter(\"in_proj_bias\", shape=[self.model_size * 3], init=self.w_init)\n",
    "        self.out_proj = hk.Linear(self.model_size, name=\"out_proj\")\n",
    "\n",
    "    def __call__(\n",
    "            self,\n",
    "            x: jnp.ndarray,\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Compute (optionally masked) MHA with queries, keys & values.\"\"\"\n",
    "        all_out = jnp.dot(x, self.in_proj_weight.transpose())\n",
    "        all_out += self.in_proj_bias\n",
    "\n",
    "        q, k, v = jnp.array_split(all_out, 3, axis=-1)\n",
    "\n",
    "        query_heads = self._split(q)\n",
    "        key_heads = self._split(k)\n",
    "        value_heads = self._split(v)\n",
    "        # RoPE\n",
    "        query_heads = apply_rope(query_heads, self.rotary_dims, seq_dim=0)\n",
    "        key_heads = apply_rope(key_heads, self.rotary_dims, seq_dim=0)\n",
    "        \n",
    "        attention_logits = jnp.einsum(\"tbhd,Tbhd->bhtT\", query_heads, key_heads)\n",
    "        sqrt_key_size = np.sqrt(self.model_size//self.num_heads).astype(k.dtype)\n",
    "        attention_logits = attention_logits / sqrt_key_size\n",
    "\n",
    "        if self.attn_mask is not None:\n",
    "            attention_logits += self.attn_mask\n",
    "\n",
    "        attention_weights = jax.nn.softmax(attention_logits)\n",
    "        attention = jnp.einsum(\"bhtT,Tbhd->tbhd\", attention_weights, value_heads)\n",
    "        # Concatenate attention matrix of all heads into a single vector.\n",
    "        attention_vec = jnp.reshape(attention, (*q.shape[:2], -1))\n",
    "\n",
    "        return self.out_proj(attention_vec)\n",
    "\n",
    "    def _split(\n",
    "            self,\n",
    "            x: jnp.ndarray,\n",
    "    ) -> jnp.ndarray:\n",
    "        return x.reshape((*x.shape[:2], self.num_heads, self.model_size//self.num_heads))\n",
    "\n",
    "\n",
    "class QuickGELU(hk.Module):\n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "        return x * jax.nn.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "class ResidualAttentionBlock(hk.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, rotary_dims:int, attn_mask: jnp.ndarray, name: str):\n",
    "        super().__init__(name=name)\n",
    "        self.attn = MultiHeadAttention(n_head, d_model // n_head, rotary_dims, 1, attn_mask, name=\"attn\")\n",
    "        self.ln_1 = LayerNorm(-1, create_scale=True, create_offset=True, name=\"ln_1\")\n",
    "        with hk.experimental.name_scope(\"mlp\"):\n",
    "            self.mlp = [hk.Linear(d_model * 4, name=\"c_fc\"),\n",
    "                        QuickGELU(),\n",
    "                        hk.Linear(d_model, name=\"c_proj\")]\n",
    "\n",
    "        self.ln_2 = LayerNorm(-1, create_scale=True, create_offset=True, name=\"ln_2\")\n",
    "\n",
    "    def run_mlp(self, x: jnp.ndarray):\n",
    "        for f in self.mlp:\n",
    "            x = f(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.run_mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(hk.Module):\n",
    "    def __init__(self, width: int, layers: int, heads: int, rotary_dims: int, name: str, attn_mask=None):\n",
    "        super().__init__(name=name)\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = [ResidualAttentionBlock(width, heads, rotary_dims, attn_mask, name=f\"resblocks{i}\") for i in range(layers)]\n",
    "        self.attn_mask = attn_mask\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "        for b in self.resblocks:\n",
    "            x = b(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifteen-preference",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/.anaconda/envs/gpt-c/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import clip_jax\n",
    "\n",
    "_, text_fn, jax_params, _ = clip_jax.load('ViT-B/32', \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extraordinary-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCLIP(hk.Module):\n",
    "    @hk.transparent\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 context_length: int,\n",
    "                 vocab_size: int,\n",
    "                 rotary_dims: int, \n",
    "                 transformer_width: int,\n",
    "                 transformer_heads: int,\n",
    "                 transformer_layers: int,\n",
    "                 seq_length:int = None\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "        if seq_length is None:\n",
    "            seq_length = context_length\n",
    "        self.seq_length = seq_length\n",
    "            \n",
    "        self.transformer = Transformer(\n",
    "            width=transformer_width,\n",
    "            layers=transformer_layers,\n",
    "            heads=transformer_heads,\n",
    "            rotary_dims=rotary_dims,\n",
    "            attn_mask=self.build_attention_mask(),\n",
    "            name=\"transformer\"\n",
    "        )\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding = hk.Embed(vocab_size, transformer_width, name=\"token_embedding\")\n",
    "\n",
    "        scale = transformer_width ** -0.5\n",
    "        w_init = hk.initializers.TruncatedNormal(1. / np.sqrt(scale))\n",
    "        self.ln_final = LayerNorm(-1, create_scale=True, create_offset=True, name=\"ln_final\")\n",
    "\n",
    "        self.text_projection = hk.get_parameter(\"text_projection\", shape=[transformer_width, embed_dim], init=w_init)\n",
    "        self.logit_scale = hk.get_parameter(\"logit_scale\", shape=[], init=hk.initializers.Constant(1))\n",
    "\n",
    "    def build_attention_mask(self):\n",
    "        # we use additive attention mask; fill with -inf\n",
    "        mask = jnp.zeros((self.seq_length, self.seq_length))\n",
    "        mask -= 10e10\n",
    "        # make zeroes in place of context windows, -inf otherwise\n",
    "        mask = jnp.triu(mask, self.context_length).transpose() + jnp.triu(mask, 1)\n",
    "        return mask\n",
    "\n",
    "    def encode(self, text):\n",
    "        x = self.token_embedding(text)  # [batch_size, d_input, d_model]\n",
    "\n",
    "        x = x.transpose((1, 0, 2))  # NLD -> LND\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.transpose((1, 0, 2))  # LND -> NLD\n",
    "        x = self.ln_final(x) @ self.text_projection\n",
    "        return x\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        x = self.encode(text)\n",
    "        # x.shape == [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the last non-zero token \n",
    "        pos = jnp.cumsum(text, axis=-1).argmax(axis=-1)\n",
    "        x = x[jnp.arange(x.shape[0]), pos] \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helpful-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(config, tokens):\n",
    "    clip = TextCLIP( # the same as orig, except context_length = 77 - 2 (special tokens)\n",
    "                     embed_dim = 512, \n",
    "                     context_length = 75, \n",
    "                     vocab_size = 49408,\n",
    "                     # can possibly vary\n",
    "                     rotary_dims = config[\"rotary_dims\"], \n",
    "                     transformer_width = config[\"d_model\"],\n",
    "                     transformer_heads = config[\"n_heads\"],\n",
    "                     transformer_layers = config[\"layers\"])\n",
    "    return clip.encode_text(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stylish-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_encode_text(config, tokens):\n",
    "    clip = TextCLIP( # the same as orig, except context_length = 77 - 2 (special tokens)\n",
    "                     embed_dim = 512, \n",
    "                     context_length = 75, \n",
    "                     vocab_size = 49408,\n",
    "                     # can possibly vary\n",
    "                     rotary_dims = config[\"rotary_dims\"], \n",
    "                     transformer_width = config[\"d_model\"],\n",
    "                     transformer_heads = config[\"n_heads\"],\n",
    "                     transformer_layers = config[\"layers\"])\n",
    "    return clip.encode_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "flush-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {    \"layers\": 12,\n",
    "    \"d_model\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"rotary_dims\": 32,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opponent-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civil-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "        encode_text = partial(cfg_encode_text,config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-vertical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-flashing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personal-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_init_fn = hk.transform(hk.experimental.optimize_rng_use(encode_text)).init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vocational-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executive-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "        key = hk.PRNGSequence(42)\n",
    "        x = jax.random.randint(next(key), (jax.local_device_count(),75), 0, 49408)\n",
    "        \n",
    "        clip_apply_fn = hk.without_apply_rng(hk.transform(encode_text)).apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "steady-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = clip_init_fn(next(key), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-times",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deluxe-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = jax.random.randint(next(key), (64,2048), 0, 49408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rocky-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len = 75\n",
    "\n",
    "def reshape_data(data):\n",
    "    # trim data to be multiple of context_len\n",
    "    chunks = data.shape[-1] // context_len\n",
    "    data = data[...,:chunks*context_len]\n",
    "    # bs, chunks*context_len -> bs*chunks, context_len\n",
    "    data = data.flatten()\n",
    "    data = data.reshape(-1, context_len)\n",
    "\n",
    "    # trim data to be multiple of (context_len, context_len)\n",
    "    chunks = data.shape[0] // context_len\n",
    "    data = data[:chunks*context_len]\n",
    "    # chunks*context_len, context_len -> chunks, context_len, context_len\n",
    "    data = data.reshape((-1, context_len, context_len))\n",
    "    # make all kind of input length - from 1 to 75 by zeroing the rest\n",
    "    return np.tril(data)\n",
    "\n",
    "def add_sot_eot(data):\n",
    "    sot_token, eot_token = 49406, 49407\n",
    "    # add sot_token to the start of each sample\n",
    "    sots = np.full((data.shape[0],context_len,1), sot_token)\n",
    "    data = np.concatenate((sots, data),axis=-1) \n",
    "    # add zeros column at end, so we can add eot_token for the last sample\n",
    "    zeroes = np.full((data.shape[0],context_len,1), 0)\n",
    "    data = np.concatenate((data, zeroes),axis=-1) \n",
    "    # make diag eot_token matrix\n",
    "    eots = np.diagflat(np.full(context_len, eot_token))\n",
    "    # move eot_token two position from diagonal\n",
    "    zeroes = np.full((context_len,2), 0)\n",
    "    eots = np.concatenate((zeroes, eots),axis=-1) \n",
    "    # place eot_token\n",
    "    return data + eots\n",
    "\n",
    "def align_to_devices(data):\n",
    "    data = data.reshape(-1, data.shape[-1])\n",
    "    chunks = data.shape[0] // jax.device_count()\n",
    "#    return data[:chunks*jax.device_count()]\n",
    "    return data[:jax.device_count()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "anonymous-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = reshape_data(xs)    \n",
    "    orig_data = add_sot_eot(data.copy())\n",
    "    \n",
    "    data, orig_data = map(align_to_devices, (data, orig_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nominated-plant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 75)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minute-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data\n",
    "xs = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cloudy-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[  62.17662  , -261.82703  ,  -53.46753  , ...,\n",
       "                 3.7723002, -105.044365 ,   15.762376 ],\n",
       "             [  84.91298  ,  -52.361774 ,  -51.79109  , ...,\n",
       "                36.110058 ,   87.18306  ,  -28.854849 ],\n",
       "             [ 106.10378  ,    5.4214125,   -1.3591211, ...,\n",
       "               -64.286476 , -159.97821  ,  -91.17958  ],\n",
       "             [-138.82695  ,  147.98439  ,  -17.922964 , ...,\n",
       "               -32.472694 , -248.58313  ,  -43.378807 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_apply_fn(params, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "killing-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.maps import mesh\n",
    "from jax.experimental.pjit import PartitionSpec, pjit, with_sharding_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "radio-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS=PartitionSpec('devices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "absolute-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "handled-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "    optimizer = optax.chain(\n",
    "        optax.scale_by_adam(),\n",
    "        optax.scale(-1),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecological-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    " def init(key, xs):\n",
    "            params = clip_init_fn(key, tokens = xs)\n",
    "            opt_state = optimizer.init(params)\n",
    "            \n",
    "            return {\n",
    "                \"params\": params,\n",
    "                \"step\": np.array(0),\n",
    "                \"opt_state\": opt_state\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "insured-topic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 75)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "generous-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/.anaconda/envs/gpt-c/lib/python3.9/site-packages/jax/experimental/pjit.py:160: UserWarning: pjit is an experimental feature and probably has bugs!\n",
      "  warn(\"pjit is an experimental feature and probably has bugs!\")\n"
     ]
    }
   ],
   "source": [
    "init_pjit = pjit(init,\n",
    "                               in_axis_resources=(None, PS),\n",
    "                               out_axis_resources=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "certain-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "    state = init_pjit(next(key), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "distinct-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "        _, clip_target, _, _ = clip_jax.load('ViT-B/32', \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-teach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adjusted-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        def train_loss(params, x, y):\n",
    "            return jnp.mean(jnp.square(clip_apply_fn(params, x) - clip_target(y)))\n",
    "            \n",
    "        def train(state, x, y):\n",
    "            val_grad_fn = jax.value_and_grad(train_loss)\n",
    "            loss, grad = val_grad_fn(state[\"params\"], x, y)\n",
    "            updates, new_opt_state = optimizer.update(grad, state[\"opt_state\"], state[\"params\"])\n",
    "            prms = optax.apply_updates(state[\"params\"], updates)\n",
    "            #stp = state[\"step\"] + 1\n",
    "            return loss, prms\n",
    "            '''\n",
    "            {\n",
    "                \"params\": optax.apply_updates(state[\"params\"], updates),\n",
    "                \"step\": state[\"step\"] + 1,\n",
    "                \"opt_state\": new_opt_state,\n",
    "            }\n",
    "            ''' \n",
    "        PS=PartitionSpec('devices')\n",
    "        train_pjit = pjit(train,\n",
    "                               in_axis_resources=(None, PS, PS),\n",
    "                               out_axis_resources=(None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pretty-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "        loss, state = train(state, data, orig_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tired-apparel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(9353.357, dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "civil-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "        loss = np.array(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fantastic-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data, orig_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "considered-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_pjit = pjit(train_loss,\n",
    "                               in_axis_resources=(None, PS, PS),\n",
    "                               out_axis_resources=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "featured-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "            val_grad_fn = jax.value_and_grad(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "thorough-serial",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_517411/1203893190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss_pjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda/envs/gpt-c/lib/python3.9/site-packages/haiku/_src/data_structures.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'params'"
     ]
    }
   ],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "    res = train_loss_pjit(state[\"params\"], x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "biblical-dayton",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_517411/1158820258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "least-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pjit = pjit(train,\n",
    "                   in_axis_resources=(None, PS, PS),\n",
    "                   out_axis_resources=(None),\n",
    "                   donate_argnums=(0,)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-colombia",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mesh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_657875/2771492860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mesh' is not defined"
     ]
    }
   ],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "        loss, state = train_pjit(state, data, orig_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-border",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = pjit(clip_target,\n",
    "                               in_axis_resources=(None, PS, None),\n",
    "                               out_axis_resources=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = clip_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-perth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-solution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-enemy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "animated-accountability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4189114/3090931802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "\u001b[0;32m~/.anaconda/envs/gpt-c/lib/python3.9/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_primals_consts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "    loss, grad = val_grad_fn(state[\"params\"], x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "        train_pjit = pjit(train,\n",
    "                               in_axis_resources=(None, PS, None),\n",
    "                               out_axis_resources=(None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-longer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "        #print(f\"shapes {obs.shape} {target.shape}\" )\n",
    "        loss, state = train_pjit(state, data, orig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "psychological-membrane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray(311684.38, dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "opening-ministry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedDeviceArray(615782.3, dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "signed-words",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "operating-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_apply_pjit = pjit(clip_apply_fn, in_axis_resources=(None, PS), out_axis_resources=PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "qualified-excellence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -45.10905   -11.829655  -10.228348 ...  -30.686451   45.81359\n",
      "    28.876823]\n",
      " [  -9.172699   21.597015   76.27464  ... -178.04343    64.722885\n",
      "   -40.204914]\n",
      " [  97.46905   -39.03131    66.35701  ...   97.62146  -145.99475\n",
      "   114.75131 ]\n",
      " [ -71.22487    17.125637   84.63946  ...  -99.49795   -37.36209\n",
      "    51.03698 ]]\n"
     ]
    }
   ],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "    result = clip_apply_pjit(params, xs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "hollywood-league",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "flying-level",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "sweet-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "        PS=PartitionSpec('devices')\n",
    "        train_pjit = pjit(train,\n",
    "                               in_axis_resources=(None, PS, PS),\n",
    "                               out_axis_resources=(None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, self.state = self.train_pjit(self.state, obs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mesh(jax.devices(), ('devices',)):\n",
    "    result = train_pjit(result, key, xs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "coordinate-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        optimizer = config[\"optimizer\"]\n",
    "        \n",
    "        _, clip_target, _, _ = clip_jax.load('ViT-B/32', \"cpu\")\n",
    "        \n",
    "        clip_init_fn = hk.transform(hk.experimental.optimize_rng_use(partial(cfg_encode_text,config))).init\n",
    "            \n",
    "        def init(key, xs):\n",
    "            params = clip_init_fn(key, xs = xs)\n",
    "            opt_state = optimizer.init(params)\n",
    "            \n",
    "            return {\n",
    "                \"params\": params,\n",
    "                \"step\": np.array(0),\n",
    "                \"opt_state\": opt_state\n",
    "            }\n",
    "\n",
    "        key = hk.PRNGSequence(42)\n",
    "        x = jax.random.randint(key, (jax.local_device_count(),75), 0, 49408)\n",
    "        \n",
    "        clip_apply_fn = hk.without_apply_rng(hk.transform(encode_text)).apply\n",
    "\n",
    "        def train_loss(params, x, y):\n",
    "            return jnp.mean(jnp.square(clip_apply_fn(params, x) - clip_target(y)))\n",
    "            \n",
    "        def train(state, x, y):\n",
    "            val_grad_fn = jax.value_and_grad(train_loss)\n",
    "            loss, grad = val_grad_fn(state[\"params\"], x, y)\n",
    "            updates, new_opt_state = optimizer.update(grad, state[\"opt_state\"], state[\"params\"])\n",
    "            \n",
    "            return loss, {\n",
    "                \"params\": optax.apply_updates(state[\"params\"], updates),\n",
    "                \"step\": state[\"step\"] + 1,\n",
    "                \"opt_state\": new_opt_state,\n",
    "            }\n",
    "        \n",
    "        PS=PartitionSpec('devices')\n",
    "        self.train_pjit \n",
    "        self.train_pjit = pjit(train,\n",
    "                               in_axis_resources=(None, PS, PS),\n",
    "                               out_axis_resources=(None))\n",
    "\n",
    "        self.eval_pjit = pjit(train_loss,\n",
    "                              in_axis_resources=(None, PS, PS),\n",
    "                              out_axis_resources=(None))\n",
    "\n",
    "        self.state = self.init(next(key), x)\n",
    "        self.eval_weights = None\n",
    "\n",
    "        param_count = hk.data_structures.tree_size(self.state['params'])\n",
    "        head_print(f\"Total parameters: {param_count * dp}\")\n",
    "\n",
    "    def write_ckpt(self, path, _):\n",
    "        write_ckpt_v2(self.state, path)\n",
    "\n",
    "    def load_ckpt(self, path):\n",
    "        self.state = load_ckpt_v2(self.state, path)\n",
    "\n",
    "    def train(self, sample):\n",
    "        obs = sample[\"obs\"]\n",
    "        target = sample[\"target\"]\n",
    "        \n",
    "        loss, self.state = self.train_pjit(self.state, obs, target)\n",
    "        loss = np.array(loss)\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "    def eval(self, sample):\n",
    "        out = self.eval_pjit(self.state[\"params\"], sample[\"obs\"], sample[\"target\"])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "inside-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from smart_open import open\n",
    "\n",
    "def write_ckpt(x, ckpt_dir):\n",
    "    pickle.dump(x['params'], open(ckpt_dir + '/params.pickle', \"wb\"))\n",
    "    pickle.dump(x['opt_state'], open(ckpt_dir + '/opt_state.pickle', \"wb\"))\n",
    "\n",
    "def read_ckpt(ckpt_dir, load_opt=True):\n",
    "    result = {'params': pickle.load(open(ckpt_dir + '/params.pickle', 'rb'))}\n",
    "    if load_opt:\n",
    "        result['opt_state'] = pickle.load(open(ckpt_dir + '/opt_state.pickle', 'rb'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from text_clip import ClipTrainer\n",
    "from tfrecord_loader import TFRecordNewInputs\n",
    "from smart_open import open\n",
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(description=\"\"\"\n",
    "    To use, download the full checkpoint archive, extract and upload to a GCS bucket, and set that as --tune-model-path\n",
    "    Modify the config file:\n",
    "        - set `model_dir` to where the checkpoints should be written during training\n",
    "        - set `train_set`, `val_set` to index files for your data\n",
    "        - set `warmup_steps`, `anneal_steps`, `lr`, `end_lr` to the lr schedule for your finetuning run\n",
    "        - the global step will reset to 0, keep that in mind when writing your lr schedule\n",
    "        - set `name` to specify the name of the Weights & Biases run\n",
    "        - set `wandb_project` to specify the Weights & Biases project to log to\n",
    "    To prepare data in the expected data format:\n",
    "        - use the script `create_finetune_tfrecords.py` in this repo to create data in the expected format\n",
    "        - upload the .tfrecords files to GCS\n",
    "        - save their GCS paths to a index file under `data/`, see existing files for examples\n",
    "    \"\"\",\n",
    "    formatter_class=argparse.RawTextHelpFormatter)\n",
    "    parser.add_argument(\"--config\", type=str, default=None, help=\"Config file location\")\n",
    "    parser.add_argument(\"--tune-model-path\", type=str, default=None, help=\"Base model to finetune\")\n",
    "    parser.add_argument(\"--fresh-opt\", default=False, action=\"store_true\", help=\"Use a newly initialized optimizer, ignoring any optimizer state saved in the base checkpoint\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "import pickle\n",
    "from smart_open import open\n",
    "\n",
    "def write_ckpt(x, ckpt_dir):\n",
    "    pickle.dump(x['params'], open(ckpt_dir + '/params.pickle', \"wb\"))\n",
    "    pickle.dump(x['opt_state'], open(ckpt_dir + '/opt_state.pickle', \"wb\"))\n",
    "\n",
    "def read_ckpt(ckpt_dir, load_opt=True):\n",
    "    result = {'params': pickle.load(open(ckpt_dir + '/params.pickle', 'rb'))}\n",
    "    if load_opt:\n",
    "        result['opt_state'] = pickle.load(open(ckpt_dir + '/opt_state.pickle', 'rb'))\n",
    "    return result\n",
    "\n",
    "def save(network, step, bucket, path, aux=None, keep_n=3, delete_old=True):\n",
    "    assert path\n",
    "    client = storage.Client()\n",
    "\n",
    "    if aux is None:\n",
    "        aux = {}\n",
    "\n",
    "    try:\n",
    "        with open(f\"gs://{bucket}/{path}/meta.json\", \"r\") as f:\n",
    "            meta = json.load(f)\n",
    "    except:\n",
    "        # create metadata file\n",
    "        with open(f\"gs://{bucket}/{path}/meta.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"step\": 0,\n",
    "                \"checkpoints\": [],\n",
    "                \"aux\": {}\n",
    "            }, f)\n",
    "\n",
    "    # do sharded checkpoint writing\n",
    "    start = time.time()\n",
    "    res = []\n",
    "    write_ckpt(network.state, f\"gs://{bucket}/{path}/step_{step}/\")\n",
    "\n",
    "    print(f\"Wrote checkpoint in {time.time() - start:.06}s\")\n",
    "\n",
    "    with open(f\"gs://{bucket}/{path}/meta.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    meta[\"step\"] = step\n",
    "    meta[\"checkpoints\"].append(step)\n",
    "    all_aux = meta.get(\"aux\", {})\n",
    "\n",
    "    while len(meta[\"checkpoints\"]) > keep_n:\n",
    "        ckpt_to_delete = meta[\"checkpoints\"].pop(0)\n",
    "\n",
    "        try:\n",
    "            del all_aux[str(ckpt_to_delete)]\n",
    "        except:\n",
    "            print(f\"failed to delete the aux state for {step}\")\n",
    "\n",
    "        if delete_old:\n",
    "            print(f\"deleting checkpoint {ckpt_to_delete}\")\n",
    "            for blob in client.list_blobs(bucket, prefix=f\"{path}/step_{ckpt_to_delete}/\"):\n",
    "                # print(f\"deleting {blob.name}\")\n",
    "                assert path in blob.name\n",
    "                blob.delete()\n",
    "        else:\n",
    "            print(f\"keeping checkpoint {ckpt_to_delete}\")\n",
    "\n",
    "    all_aux[step] = aux\n",
    "    meta[\"aux\"] = all_aux\n",
    "\n",
    "    with open(f\"gs://{bucket}/{path}/meta.json\", \"w\") as f:\n",
    "        json.dump(meta, f)\n",
    "\n",
    "def gpt3_schedule(warmup_steps,\n",
    "                  total_steps,\n",
    "                  peak_lr,\n",
    "                  end_lr):\n",
    "    def sch(step):\n",
    "        warmup_pct = jnp.clip(step, 0, warmup_steps) / warmup_steps\n",
    "        anneal_pct = jnp.clip(step - warmup_steps, 0, total_steps) / total_steps\n",
    "\n",
    "        return warmup_pct * peak_lr - (peak_lr - end_lr) * (1 - jnp.cos(jnp.pi * anneal_pct)) / 2\n",
    "\n",
    "    return sch\n",
    "\n",
    "context_len = 75\n",
    "\n",
    "def reshape_data(data):\n",
    "    # trim data to be multiple of context_len\n",
    "    chunks = data.shape[-1] // context_len\n",
    "    data = data[...,:chunks*context_len]\n",
    "    # bs, chunks*context_len -> bs*chunks, context_len\n",
    "    data = data.flatten()\n",
    "    data = data.reshape(-1, context_len)\n",
    "\n",
    "    # trim data to be multiple of (context_len, context_len)\n",
    "    chunks = data.shape[0] // context_len\n",
    "    data = data[:chunks*context_len]\n",
    "    # chunks*context_len, context_len -> chunks, context_len, context_len\n",
    "    data = data.reshape((-1, context_len, context_len))\n",
    "    # make all kind of input length - from 1 to 75 by zeroing the rest\n",
    "    return np.tril(data)\n",
    "\n",
    "def add_sot_eot(data):\n",
    "    sot_token, eot_token = 49406, 49407\n",
    "    # add sot_token to the start of each sample\n",
    "    sots = np.full((data.shape[0],context_len,1), sot_token)\n",
    "    data = np.concatenate((sots, data),axis=-1) \n",
    "    # add zeros column at end, so we can add eot_token for the last sample\n",
    "    zeroes = np.full((data.shape[0],context_len,1), 0)\n",
    "    data = np.concatenate((data, zeroes),axis=-1) \n",
    "    # make diag eot_token matrix\n",
    "    eots = np.diagflat(np.full(context_len, eot_token))\n",
    "    # move eot_token two position from diagonal\n",
    "    zeroes = np.full((context_len,1), 0)\n",
    "    eots = np.concatenate((zeroes, eots),axis=-1) \n",
    "    eots = np.concatenate((zeroes, eots),axis=-1) \n",
    "    # place eot_token\n",
    "    return data + eots\n",
    "\n",
    "def network_step(network, data):\n",
    "    data = reshape_data(data)    \n",
    "    orig_data = add_sot_eot(data.copy())\n",
    "    \n",
    "    data = data.reshape(-1, context_len)\n",
    "    orig_data = orig_data.reshape(-1, context_len+2)\n",
    "    \n",
    "    inputs = {\n",
    "        \"obs\": data,\n",
    "        \"target\": orig_data,\n",
    "    }\n",
    "\n",
    "    return network.train(inputs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    params = json.load(open(args.config))\n",
    "\n",
    "    gradient_accumulation_steps = params.get(\"gradient_accumulation_steps\", 1)\n",
    "    batch_size = params[\"batch_size\"]\n",
    "\n",
    "    assert cores_per_replica <= 8\n",
    "\n",
    "    bucket = params[\"bucket\"]\n",
    "    model_dir = params[\"model_dir\"]\n",
    "    layers = params[\"layers\"]\n",
    "    d_model = params[\"d_model\"]\n",
    "    n_heads = params[\"n_heads\"]\n",
    "\n",
    "    val_batches = params[\"val_batches\"]\n",
    "    val_every = params[\"val_every\"]\n",
    "    ckpt_every = params[\"ckpt_every\"]\n",
    "    keep_every = params[\"keep_every\"]\n",
    "    total_steps = params[\"total_steps\"]\n",
    "\n",
    "    warmup_steps = params[\"warmup_steps\"]\n",
    "    anneal_steps = params[\"anneal_steps\"]\n",
    "    lr = params[\"lr\"]\n",
    "    end_lr = params[\"end_lr\"]\n",
    "    weight_decay = params[\"weight_decay\"]\n",
    "   \n",
    "    # alpha parameter for the exponential moving averages used to compute B_simple\n",
    "    noise_scale_alpha = params.get(\"noise_scale_alpha\", 0.01)\n",
    "\n",
    "    scheduler = gpt3_schedule(warmup_steps, anneal_steps, lr, end_lr)\n",
    "    \n",
    "    opt = optax.chain(\n",
    "        optax.scale(1 / gradient_accumulation_steps),\n",
    "        optax.clip_by_global_norm(1),\n",
    "        optax.scale_by_adam(),\n",
    "        optax.add_decayed_weights(weight_decay),\n",
    "        optax.scale(-1),\n",
    "        optax.scale_by_schedule(scheduler)\n",
    "    )\n",
    "\n",
    "    params[\"optimizer\"] = opt\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"jax devices: {jax.device_count()}\")\n",
    "    print(f\"jax runtime initialized in {time.time() - start:.06}s\")\n",
    "\n",
    "    devices = jax.devices()\n",
    "\n",
    "    # pick initial ckpt - based on tuning vs train from scratch\n",
    "\n",
    "    step = 0\n",
    "    initial_ckpt_state_path = None\n",
    "    train_loader = None\n",
    "\n",
    "    if args.tune_model_path:\n",
    "        print('`--tune_model_path` passed: we are beginning a fine-tuning run')\n",
    "        fine_tuning = True\n",
    "        initial_ckpt_state_path = args.tune_model_path\n",
    "    else:\n",
    "        print('`--tune_model_path` not passed: we are continuing a fine-tuning run from a checkpoint (or we are not fine-tuning)')\n",
    "        fine_tuning = False\n",
    "        initial_ckpt_model_dir = model_dir\n",
    "        initial_ckpt_path = f\"gs://{bucket}/{initial_ckpt_model_dir}\"\n",
    "        meta_path = f\"{initial_ckpt_path}/meta.json\"\n",
    "\n",
    "        try:\n",
    "            with open(meta_path, \"r\") as f:\n",
    "                meta = json.load(f)\n",
    "            ckpt_step = meta[\"checkpoints\"][-1]\n",
    "            initial_ckpt_state_path = f\"{initial_ckpt_path}/step_{ckpt_step}/\"\n",
    "            print(f\"state will be restored from checkpoint {ckpt_step}\")\n",
    "\n",
    "            step = ckpt_step\n",
    "            train_loader = meta['aux'][str(ckpt_step)].get(\"train_loader\", None)\n",
    "        except NotFound:\n",
    "            # no checkpoint, start at zero\n",
    "            print(f\"No checkpoint to load at {initial_ckpt_path}. Training from scratch.\")\n",
    "\n",
    "    if initial_ckpt_state_path:\n",
    "        print(f\"path to load checkpoint from: {initial_ckpt_state_path}\")\n",
    "    else:\n",
    "        print(\"not loading from a checkpoint\")\n",
    "\n",
    "    # set up datasets\n",
    "    print(\"setting up datasets\")\n",
    "\n",
    "    train_dataset = TFRecordNewInputs(f\"data/{params['train_set']}\",\n",
    "                                      batch_size=(\n",
    "                                          gradient_accumulation_steps,\n",
    "                                          batch_size),\n",
    "                                      sample_size=2048,\n",
    "                                      restore_state=train_loader)\n",
    "\n",
    "    val_sets = {}\n",
    "\n",
    "    for k, v in params[\"val_set\"].items():\n",
    "        val_sets[k] = TFRecordNewInputs(\n",
    "            f\"data/{v}\", batch_size=(batch_size,), sample_size=seq\n",
    "        )\n",
    "\n",
    "    # tok/sec metrics\n",
    "    sequences_per_step = gradient_accumulation_steps * batch_size * (2048//context_len)\n",
    "\n",
    "    # load + run\n",
    "    with jax.experimental.maps.mesh(devices, ('devices',)):\n",
    "        print(\"initializing network\")\n",
    "        network = ClipTrainer(params)\n",
    "\n",
    "        if initial_ckpt_state_path:\n",
    "            print(\"loading network\")\n",
    "            if fine_tuning:\n",
    "                # get the scheduler step stored in the just-initialized optimizer\n",
    "                # should be zero\n",
    "                init_sched_state = network.state[\"opt_state\"][-1]\n",
    "\n",
    "            start = time.time()\n",
    "            network.state = read_ckpt(network.state, initial_ckpt_state_path, devices.shape[1], load_opt=(not args.fresh_opt))\n",
    "\n",
    "            if fine_tuning:\n",
    "                # overwrite the loaded scheduler step with zeros\n",
    "                # this makes fine-tuning use the lr schedule in\n",
    "                network.state[\"opt_state\"][-1] = init_sched_state\n",
    "\n",
    "            print(f\"network loaded in {time.time() - start:.06}s\")\n",
    "\n",
    "        print('compiling train fn')\n",
    "        start = time.time()\n",
    "        loss = network_step(network, train_dataset.get_samples())\n",
    "        step += 1\n",
    "        print(f\"Train fn compiled in {time.time() - start:.06}s\")\n",
    "\n",
    "        print('compiling eval fn')\n",
    "        start = time.time()\n",
    "        for val_set in val_sets.values():\n",
    "            network_step(network, val_set.get_samples())\n",
    "            val_set.reset()\n",
    "        print(f\"Eval fn compiled in {time.time() - start:.06}s\")\n",
    "        '''\n",
    "        project = params.get(\"wandb_project\", \"text-clip\")\n",
    "        wandb.init(project=project, name=params[\"name\"], config=params)\n",
    "        '''\n",
    "        while True:\n",
    "            if (step % ckpt_every == 1) or step == total_steps:\n",
    "                print(f\"saving a checkpoint for step {step}\")\n",
    "                save(network, step, bucket, model_dir,\n",
    "                     aux={\"train_loader\": train_dataset.get_state()},\n",
    "                     delete_old=True,\n",
    "                     )\n",
    "\n",
    "            if step % val_every == 1:  # 1 because we've already taken a step to compile train fn\n",
    "                for name, val_set in val_sets.items():\n",
    "                    val_loss = []\n",
    "                    for i, _ in tqdm(zip(val_set.sample_once(), range(val_batches)),\n",
    "                                     desc=f\"validation for step {step}, set {name}\",\n",
    "                                     total=val_batches):\n",
    "                        val_loss.append(network_step(network, i))\n",
    "                    val_set.reset()\n",
    "\n",
    "                    val_loss = np.array(val_loss).mean()\n",
    "                    print(f\"validation loss for step {step}, set {name}: {val_loss}\")\n",
    "\n",
    "                    #wandb.log({f'val/loss_{name}': float(val_loss)}, step)\n",
    "\n",
    "            if step == total_steps:\n",
    "                print(\"training completed!\")\n",
    "                exit()\n",
    "\n",
    "            start = time.time()\n",
    "            loss = network_step(network, train_dataset.get_samples())\n",
    "            step += 1\n",
    "\n",
    "            steps_per_sec = 1 / (time.time() - start)\n",
    "            sequences_processed = sequences_per_step * step\n",
    "\n",
    "            ### compute summary stats about the gradient\n",
    "\n",
    "            # converts from grads-summed-over-microbatch (what `CasualTransformer.train` computes)\n",
    "            # to grads-averaged-over-microbatch (what we want)\n",
    "            #\n",
    "            # (when taking gradient steps, the same conversion happens inside the optimizer\n",
    "            #  via optax.scale(1 / gradient_accumulation_steps))\n",
    "            \n",
    "            '''\n",
    "            wandb_stats = {\n",
    "                \"train/loss\": loss,\n",
    "                \"train/steps_per_sec\": steps_per_sec,\n",
    "                \"train/tokens_per_sec\": tokens_per_sec,\n",
    "                \"train/learning_rate\": float(scheduler(network.state[\"opt_state\"][-1].count[0].item())),\n",
    "                \"sequences_processed\": sequences_processed,\n",
    "            }\n",
    "            wandb_stats.update(noise_scale_stats)\n",
    "\n",
    "            wandb.log(wandb_stats, step)\n",
    "            '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpt-c]",
   "language": "python",
   "name": "conda-env-gpt-c-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
